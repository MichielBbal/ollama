{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c409dcaf",
   "metadata": {},
   "source": [
    "# Ollama Self driving Challenges\n",
    "\n",
    "Self driving car challenges\n",
    "\n",
    "### Contents\n",
    "0. Install and settings\n",
    "1. Using ollama vision with LLaVA\n",
    "2. LLaVA tests\n",
    "3. Webcam challenge\n",
    "4. Self driving car challenge\n",
    "5. Bonus Challenge: Gradio front end\n",
    "\n",
    "\n",
    "### Sources\n",
    "- ollama: www.ollama.com\n",
    "- ollama python: https://github.com/ollama/ollama-python\n",
    "- LLaVA: https://llava-vl.github.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5669c8d4",
   "metadata": {},
   "source": [
    "## 0. Install and settings\n",
    "\n",
    "Make sure you've installed Ollama on your machine before running the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "362cea4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.9\n"
     ]
    }
   ],
   "source": [
    "# Check your version of python. To run ollama you will need Python 3.8 or higher.\n",
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd224ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull models from source; uncomment if necessery\n",
    "import ollama\n",
    "#ollama.pull('llava')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4446fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script that shows the models on your laptop.\n",
    "import ollama\n",
    "models_dict = ollama.list()\n",
    "models = models_dict['models']\n",
    "model_list = []\n",
    "for i in range(len(models)):\n",
    "    print(models[i]['name'])\n",
    "    model_list.append(models[i]['name'])\n",
    "print(50*'-')\n",
    "print(model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a0022",
   "metadata": {},
   "source": [
    "## 1. Using ollama vision with LLaVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e352965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the jpg files in your current folder\n",
    "import glob\n",
    "my_jpgs = glob.glob('*.jpg')\n",
    "my_jpgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d24d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select your image here\n",
    "image_path = 'man_ironing_taxi.jpg' #select your image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e19bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show an image\n",
    "import IPython\n",
    "IPython.display.Image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a88c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://github.com/ollama/ollama-python\n",
    "import ollama\n",
    "\n",
    "res = ollama.chat(\n",
    "    model=\"llava\",\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'What is strange about this image?:',\n",
    "            'images': [image_path]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(res['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8843ba2",
   "metadata": {},
   "source": [
    "## 2. LLaVA Self driving car challenge\n",
    " \n",
    "Tesla's (still) use an older Object Detection model, where they trained a model based on a large set om images (super-vised learning). However, this model is worse than Llava. See for yourself with these exercises! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c24de28",
   "metadata": {},
   "source": [
    "### Exercise 1: Man on Bus\n",
    "\n",
    "Use image 'man_on_bus.jpg' en let LLaVA describe the image. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627ccb80",
   "metadata": {},
   "source": [
    "![Tesla displayed this](tesla_man_bus.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe60a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57c06e",
   "metadata": {},
   "source": [
    "P.S. The image of a cow on the beach is a classic in Computer Vision as previous generation of models (CNN's) were not able to detect the cow on the beach. (see https://arxiv.org/abs/1807.04975 Recognition in Terra Incognita). Now LLaVA can do it with ease. Progress!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e1f4a",
   "metadata": {},
   "source": [
    "### Exercise 2:  Truck in the dark\n",
    "\n",
    "A horrible accident happened when a self driving tesla missed a truck crossing the road in the dark.\n",
    "https://www.youtube.com/watch?v=7oprWTnnBqM \n",
    "Would Llava do better?\n",
    "\n",
    "Use image 'truck_in_dark.jpg'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a92f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f91da",
   "metadata": {},
   "source": [
    "### Exercise 3: Stop or not?\n",
    "Read the following article: https://www.carscoops.com/2024/05/t-shirt-with-stop-sign-on-it-fools-waymos-autonomous-vehicles/\n",
    "Use image 'stop_sign.jpg'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17532bb0",
   "metadata": {},
   "source": [
    "### Exercise 4: Cruise taxi missed a striped tape and famously got stuck in the wet concrete.\n",
    "\n",
    "What does LLaVA make of this (comparable) situation?\n",
    "Use image 'afzetlint.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6500f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37c1d4b",
   "metadata": {},
   "source": [
    "### Exercise 5: select your own image\n",
    "Select an image from the web & let ollama describe it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9984c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf263fc",
   "metadata": {},
   "source": [
    "### Short summary\n",
    "\n",
    "Give a short summary how good LLaVA performs at these tasks.\n",
    "- image 1:\n",
    "- image 2:\n",
    "- image 3:\n",
    "- image 4:\n",
    "- image 5:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
