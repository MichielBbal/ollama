{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "\n",
    "A notebook that combines all the technologies we've used in the 3 workshops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Install dependencies and packages\n",
    " \n",
    "Make sure you have installed the following dependencies:\n",
    "\n",
    "- ffmpeg - download and install from www.ffmpeg.org. \n",
    "- pyaudio - Windows: install with pip (below). MacOS/Linux see instruction at https://pypi.org/project/PyAudio/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following packages:\n",
    "1. pyAudio - for the microphone\n",
    "2. py3-tts - to do Text to Speech. This uses your OS + uses wheel package to install it properly\n",
    "3. whisper - to do Speech to Text\n",
    "4. SpeechRecognition - wrapper for microphone input and sending it to whisper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyAudio\n",
    "%pip install --upgrade wheel\n",
    "%pip install py3-tts\n",
    "%pip install git+https://github.com/openai/whisper.git \n",
    "%pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check version of pyaudio\n",
    "import pyaudio\n",
    "pyaudio.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings. Adjust for your own preference.\n",
    "model = 'tinyllama'\n",
    "language = 'english' # language for speech recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only use if ollama is not running in background\n",
    "!ollama serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: this example requires PyAudio because it uses the Microphone class\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "# obtain audio from the microphone\n",
    "r = sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Say something!\")\n",
    "    audio = r.listen(source)\n",
    "\n",
    "# recognize speech using whisper and assign to variable 'question'\n",
    "try:\n",
    "    question = r.recognize_whisper(audio, language=language)\n",
    "    print(\"Whisper thinks you said: \" + question)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Whisper could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(f\"Could not request results from Whisper; {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call ollama using the variable 'question'\n",
    "import ollama\n",
    "\n",
    "def ask_ollama(question):\n",
    "    \"\"\"\n",
    "    \n",
    "    Sends a question to the Ollama API and returns the response.\n",
    "    \"\"\"\n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {'role': 'user', 'content': question},\n",
    "        ],\n",
    "    )\n",
    "    global answer\n",
    "    answer = response['message']['content']\n",
    "    print(answer)\n",
    "\n",
    "# Example usage\n",
    "ask_ollama(question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to speech function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text to speech function using the answer from ollama\n",
    "import pyttsx3\n",
    "\n",
    "def speak_text(answer):\n",
    "    \"\"\"\n",
    "    Converts the given text to speech using the pyttsx3 library.\n",
    "    \"\"\"\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(answer)\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Example usage\n",
    "#answer = \"This is the text to be spoken.\"\n",
    "speak_text(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenges"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
